{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Semisupervised_framework.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6uMIS6RsYapk",
        "EvUCvVk7dvjS",
        "l-TammunGCAM",
        "80eYUtNZGKHM",
        "FmJBZ4KZGOaM",
        "gVAQYaXxOM4c",
        "T3c7UxI4-E_L",
        "qV9L90kQOCO6"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uMIS6RsYapk"
      },
      "source": [
        "# Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EIbOdwiYapq"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import torch\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import gensim\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.data import load\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "import nltk\n",
        "import spacy\n",
        "import networkx as nx\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "data_path = 'data'\n",
        "\n",
        "propheno_df = pd.read_csv(os.path.join(data_path, 'propheno_scoms.csv'))\n",
        "propheno_df = propheno_df.dropna()\n",
        "propheno_df = propheno_df[['Sentence', 'Protein', 'UniProtId', 'Phenotype', 'HPOId', 'Type']]\n",
        "propheno_df = propheno_df[propheno_df['Protein'].str.len() > 1]\n",
        "propheno_df = propheno_df[propheno_df['Sentence'].str.len() < 500]\n",
        "propheno_df = propheno_df[~propheno_df.Sentence.str.contains('Abbreviations')]\n",
        "propheno_df = propheno_df[~(propheno_df['Sentence'].str.contains(';') & (propheno_df['Sentence'].str.contains(':') | propheno_df['Sentence'].str.contains(',')))]\n",
        "propheno_df.reset_index(inplace=True)\n",
        "\n",
        "train_df = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
        "validation_df = pd.read_csv(os.path.join(data_path, 'validation.csv'))\n",
        "test_df = pd.read_csv(os.path.join(data_path, 'test.csv'))\n",
        "\n",
        "pretrained_w2v = gensim.models.Word2Vec.load(os.path.join(data_path, 'word2vec_100_10_5.model'))\n",
        "\n",
        "MAX_LEN = 80\n",
        "SHORT_MAX_LEN = 25\n",
        "MAX_WORDS = 30000\n",
        "OOV_TOKEN = 'OOV'\n",
        "TRUNCATE_MODE = 'post'\n",
        "PADDING_MODE = 'post'\n",
        "EMBEDDING_SIZE = 100\n",
        "\n",
        "all_proteins = set(propheno_df['UniProtId'])\n",
        "all_phenotypes = set(propheno_df['HPOId'])\n",
        "\n",
        "class DynamicDataset(Dataset):\n",
        "    def __init__(self, sequences, features, short_sequences, labels):\n",
        "        self.sequences = sequences\n",
        "        self.features = features\n",
        "        self.short_sequences = short_sequences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sequences[i], self.features[i], self.short_sequences[i], self.labels[i]) \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvUCvVk7dvjS"
      },
      "source": [
        "# Preprocessing (Load pickles)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aJUrcKhh17n"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "seed = 0\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(1)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "with open(os.path.join(data_path, 'sequences_labels.pkl'), 'rb') as handle:\n",
        "    [train_sequences, train_features, train_sp_sequences, train_labels, val_sequences, val_features, val_sp_sequences, val_labels, \n",
        "    test_sequences, test_features, test_sp_sequences, test_labels, propheno_sequences, propheno_features, propheno_labels] = pickle.load(handle)\n",
        "    \n",
        "with open(os.path.join(data_path, 'propheno_masks.pkl'), 'rb') as handle:\n",
        "    [propheno_inputs, propheno_masks, propheno_labels] = pickle.load(handle)\n",
        "\n",
        "with open(os.path.join(data_path, 'tokenizer.pkl'), 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "with open(os.path.join(data_path, 'propheno_short.pkl'), 'rb') as handle:\n",
        "    propheno_sp_sequences = pickle.load(handle)\n",
        "\n",
        "with open(os.path.join(data_path, 'bert_predictions_propheno_new.pkl'), 'rb') as handle:\n",
        "    [bert_propheno_predictions_scores, bert_propheno_flat_predictions, bert_propheno_true_labels] = pickle.load(handle)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "\n",
        "weights_matrix = np.zeros((vocab_size+1, EMBEDDING_SIZE))\n",
        "for i, word in enumerate(tokenizer.word_index, start=1):\n",
        "    try: \n",
        "        weights_matrix[i] = pretrained_w2v.wv[word]\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(EMBEDDING_SIZE, ))\n",
        "\n",
        "train = DynamicDataset(train_sequences, train_features, train_sp_sequences, train_labels)\n",
        "validation = DynamicDataset(val_sequences, val_features, val_sp_sequences, val_labels)\n",
        "test = DynamicDataset(test_sequences, test_features, test_sp_sequences, test_labels)\n",
        "propheno = DynamicDataset(propheno_sequences, propheno_features, propheno_sp_sequences, propheno_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-TammunGCAM"
      },
      "source": [
        "# Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv8hgHezqzSr"
      },
      "source": [
        "seed = 0\n",
        "\n",
        "class MultiCnn(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        torch.manual_seed(seed)\n",
        "        super(MultiCnn, self).__init__()\n",
        "        ### Original Sentence\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.word_embeddings.weight.data.copy_(torch.from_numpy(weights_matrix))\n",
        "        self.conv1 = nn.Conv1d(embedding_size, 64, 3)\n",
        "        self.drop1 = nn.Dropout(0.5)\n",
        "        self.max_pool1 = nn.MaxPool1d(2)\n",
        "        self.flat1 = nn.Flatten()\n",
        "\n",
        "        self.conv2 = nn.Conv1d(embedding_size, 64, 5)\n",
        "        self.drop2 = nn.Dropout(0.5)\n",
        "        self.max_pool2 = nn.MaxPool1d(2)\n",
        "        self.flat2 = nn.Flatten()\n",
        "        \n",
        "        ### Shortest Path\n",
        "        self.s_word_embeddings = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.s_word_embeddings.weight.data.copy_(torch.from_numpy(weights_matrix))\n",
        "        self.s_conv1 = nn.Conv1d(embedding_size, 64, 3)\n",
        "        self.s_drop1 = nn.Dropout(0.3)\n",
        "        self.s_max_pool1 = nn.MaxPool1d(2)\n",
        "        self.s_flat1 = nn.Flatten()\n",
        "\n",
        "        self.s_conv2 = nn.Conv1d(embedding_size, 64, 5)\n",
        "        self.s_drop2 = nn.Dropout(0.3)\n",
        "        self.s_max_pool2 = nn.MaxPool1d(2)\n",
        "        self.s_flat2 = nn.Flatten()\n",
        "        \n",
        "        ### Concatenate\n",
        "        self.fc1 = nn.Linear(64*98, 100)\n",
        "        self.drop4 = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(100, 64)\n",
        "        self.drop5 = nn.Dropout(0.2)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, sentence, features, shortest):\n",
        "        embedding = self.word_embeddings(sentence).permute(0, 2, 1)\n",
        "        short_embedding = self.s_word_embeddings(shortest).permute(0, 2, 1)\n",
        "        \n",
        "        conv1 = F.relu(self.conv1(embedding))\n",
        "        drop1 = self.drop1(conv1)\n",
        "        max_pool1 = self.max_pool1(drop1)\n",
        "        flat1 = self.flat1(max_pool1)\n",
        "        \n",
        "        conv2 = F.relu(self.conv2(embedding))\n",
        "        drop2 = self.drop2(conv2)\n",
        "        max_pool2 = self.max_pool2(drop2)\n",
        "        flat2 = self.flat2(max_pool2)\n",
        "    \n",
        "        short_conv1 = F.relu(self.s_conv1(short_embedding))\n",
        "        short_drop1 = self.s_drop1(short_conv1)\n",
        "        short_max_pool1 = self.s_max_pool1(short_drop1)\n",
        "        short_flat1 = self.s_flat1(short_max_pool1)\n",
        "        \n",
        "        short_conv2 = F.relu(self.s_conv2(short_embedding))\n",
        "        short_drop2 = self.s_drop2(short_conv2)\n",
        "        short_max_pool2 = self.s_max_pool2(short_drop2)\n",
        "        short_flat2 = self.s_flat2(short_max_pool2)\n",
        "        \n",
        "        cat = torch.cat((flat1, flat2, short_flat1, short_flat2), dim=1)\n",
        "        \n",
        "        fc1 = F.relu(self.fc1(cat.view(len(sentence), -1)))\n",
        "        drop4 = self.drop4(fc1)\n",
        "        fc2 = F.relu(self.fc2(drop4))\n",
        "        drop5 = self.drop5(fc2)\n",
        "        fc3 = torch.sigmoid(self.fc3(drop5))\n",
        "        \n",
        "        return fc3\n",
        "\n",
        "class BiLSTMShort(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        torch.manual_seed(seed)\n",
        "        super(BiLSTMShort, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.word_embeddings.weight.data.copy_(torch.from_numpy(weights_matrix))\n",
        "        self.bi_lstm1 = nn.LSTM(embedding_size, 32, bidirectional=True)\n",
        "        self.bi_lstm2 = nn.LSTM(embedding_size, 32, bidirectional=True)\n",
        "\n",
        "        self.fc1 = nn.Linear(64*105, 100)\n",
        "        self.drop1 = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(100, 64)\n",
        "        self.drop2 = nn.Dropout(0.2)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, sentence, features, shortest):\n",
        "        embedding = self.word_embeddings(sentence)\n",
        "        short_embedding = self.word_embeddings(shortest)\n",
        "        lstm_out1, hidden1 = self.bi_lstm1(embedding)\n",
        "        short_lstm_out1, short_hidden1 = self.bi_lstm2(short_embedding)\n",
        "        cat = torch.cat((lstm_out1.permute(0, 2, 1), short_lstm_out1.permute(0, 2, 1)), dim=2)\n",
        "        \n",
        "        fc1 = F.relu(self.fc1(cat.view(len(sentence), -1)))\n",
        "        drop1 = self.drop1(fc1)\n",
        "        fc2 = F.relu(self.fc2(drop1))\n",
        "        drop2 = self.drop2(fc2)\n",
        "        fc3 = torch.sigmoid(self.fc3(drop2))\n",
        "        return fc3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80eYUtNZGKHM"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqTCjLDjYarF"
      },
      "source": [
        "def print_performance(preds, true_labels):\n",
        "    print('Precision: {0:4.3f}, Recall: {1:4.3f}, F1: {2:4.3f}, AUROC: {3:4.3f}'.format(precision_score(true_labels, preds), recall_score(true_labels, preds), f1_score(true_labels, preds), roc_auc_score(true_labels, preds)))\n",
        "    print('tn={0:d}, fp={1:d}, fn={2:d}, tp={3:d}'.format(*confusion_matrix(true_labels, preds).ravel()))\n",
        "    print('{0:4.3f} {1:4.3f} {2:4.3f} {3:4.3f}'.format(precision_score(true_labels, preds), recall_score(true_labels, preds), f1_score(true_labels, preds), roc_auc_score(true_labels, preds)))\n",
        "    \n",
        "def train_model(model, dataset, epochs=20, echo=False):\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    loader = DataLoader(dataset, batch_size=32)\n",
        "\n",
        "    # model.train()\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        progress = tqdm(loader, leave=False) # tqdm_notebook\n",
        "        tqdm._instances.clear()\n",
        "        for inputs, features, short, target in progress:\n",
        "            model.zero_grad()\n",
        "            output = model(inputs.to(device), features.to(device), short.to(device))\n",
        "            loss = criterion(output, target.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tqdm._instances.clear()\n",
        "        if echo:\n",
        "            print(epoch, loss)\n",
        "    return model\n",
        "\n",
        "def concatenate_sequences(sequences, features, shorts, labels, added_sequences, added_features, added_shorts, added_labels):\n",
        "    sequences = torch.cat((sequences, added_sequences))\n",
        "    features = np.concatenate((features, added_features))\n",
        "    shorts = np.concatenate((shorts, added_shorts))\n",
        "    labels = torch.cat((labels, added_labels))\n",
        "    return sequences, features, shorts, labels\n",
        "\n",
        "def eval_model(model, dataset, indices=None, return_binary=False, threshold=None):\n",
        "    if indices is not None:\n",
        "        dataset = DynamicDataset(dataset[indices][0], dataset[indices][1], dataset[indices][2], dataset[indices][3])\n",
        "    \n",
        "    loader = DataLoader(dataset, batch_size=32)\n",
        "    predictions , true_labels = [], []\n",
        "    model.eval()\n",
        "    cnt = 0\n",
        "    for batch in loader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs, features, shorts, labels = batch\n",
        "        with torch.no_grad():\n",
        "            logits = model(inputs.to(device), features.to(device), shorts.to(device))\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "        \n",
        "        cnt += 1\n",
        "        if threshold and cnt == threshold:\n",
        "            break\n",
        "    \n",
        "    predictions = [item for sublist in predictions for item in sublist]\n",
        "    if return_binary:\n",
        "        predictions = np.array([1 if pred[0] > 0.5 else 0 for pred in predictions])\n",
        "    labels = [item[0] for sublist in true_labels for item in sublist]\n",
        "    \n",
        "    return predictions, labels\n",
        "\n",
        "def print_stats(dataset):\n",
        "    print('Length of input dataset: {0:d}'.format(len(dataset)))\n",
        "    print('Positive instances: {0:d} ({1:4.2f}), Negative instances: {2:d} ({3:4.2f})'.format(sum(dataset.labels == 1)[0], int(sum(dataset.labels == 1)[0]) / len(dataset), sum(dataset.labels == 0)[0], int(sum(dataset.labels == 0)[0]) / len(dataset)))\n",
        "    \n",
        "def create_model(input_value, model_type='all', network=None):\n",
        "    model = network(vocab_size+1, EMBEDDING_SIZE)\n",
        "    model.cuda()\n",
        "    print_stats(train)\n",
        "    model = train_model(model, train)\n",
        "\n",
        "    print_performance(*eval_model(model, validation, return_binary=True))\n",
        "    \n",
        "    indices = None\n",
        "    if model_type == 'uniprot':\n",
        "        # indices = list(uniprot_indices[input_value])\n",
        "        indices = propheno_df[propheno_df.UniProtId == input_value].index.to_numpy()\n",
        "    elif model_type == 'hpo':\n",
        "        # indices = list(hpo_indices[input_value])\n",
        "        indices = propheno_df[propheno_df.HPOId == input_value].index.to_numpy()\n",
        "    predictions, labels = eval_model(model, propheno, indices=indices)\n",
        "    \n",
        "    instances = []\n",
        "    label_instances = []\n",
        "    \n",
        "    instance_threshold = 1000 \n",
        "    max_cnt = 0\n",
        "\n",
        "    if model_type == 'all':\n",
        "        for i in range(len(predictions)):\n",
        "            if predictions[i][0] <= 0.02:\n",
        "                instances.append(i)\n",
        "        pos_cnt = len(instances)\n",
        "        for i in range(len(predictions)):\n",
        "            if pos_cnt == 0:\n",
        "                break\n",
        "            if predictions[i][0] >= 0.98:\n",
        "                instances.append(i)\n",
        "                pos_cnt -= 1\n",
        "    else:\n",
        "        for i, idx in enumerate(indices):\n",
        "            if predictions[i][0] <= 0.02:\n",
        "                instances.append(idx)\n",
        "                label_instances.append(i)\n",
        "                max_cnt += 1\n",
        "                if max_cnt == instance_threshold:\n",
        "                    break\n",
        "        pos_cnt = len(instances)\n",
        "        for i, idx in enumerate(indices):\n",
        "            if pos_cnt == 0:\n",
        "                break\n",
        "            if predictions[i][0] >= 0.98:\n",
        "                instances.append(idx)\n",
        "                label_instances.append(i)\n",
        "                pos_cnt -= 1\n",
        "    \n",
        "    instances = np.array(instances, dtype=int)\n",
        "    label_instances = np.array(label_instances, dtype=int)\n",
        "    predictions = np.array([1 if pred[0] > 0.5 else 0 for pred in predictions])\n",
        "    added_sequences, added_features, added_shorts, added_labels = concatenate_sequences(train_sequences, train_features, train_sp_sequences, train_labels, \n",
        "                                                                                        propheno_sequences[instances], propheno_features[instances], propheno_sp_sequences, \n",
        "                                                                                        torch.from_numpy(predictions[label_instances].reshape(-1, 1)).float())\n",
        "\n",
        "    dataset = DynamicDataset(added_sequences, added_features, added_shorts, added_labels)\n",
        "    print_stats(dataset)\n",
        "    model = train_model(model, dataset)\n",
        "\n",
        "    print_performance(*eval_model(model, validation, return_binary=True))\n",
        "    \n",
        "    save_model(model, input_value.replace(':', ''), model_type=model_type)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmJBZ4KZGOaM"
      },
      "source": [
        "# Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY9-C_4YYarN"
      },
      "source": [
        "seed = 0\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(1)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "train = DynamicDataset(train_sequences, train_features, train_sp_sequences, train_labels)\n",
        "\n",
        "def run_model(network):\n",
        "    model = network(vocab_size+1, EMBEDDING_SIZE)\n",
        "    model.cuda()\n",
        "    EPOCHS = 20\n",
        "    train_model(model, train, epochs=EPOCHS, echo=True)\n",
        "    return model\n",
        "\n",
        "time1 = time.time()\n",
        "rnn_model = run_model(BiLSTMShort)\n",
        "time2 = time.time()\n",
        "print(time2 - time1)\n",
        "time1 = time.time()\n",
        "cnn_model = run_model(MultiCnn)\n",
        "time2 = time.time()\n",
        "print(time2 - time1)\n",
        "\n",
        "predictions, true_labels = eval_model(rnn_model, test, return_binary=True)\n",
        "print_performance(predictions, true_labels)\n",
        "\n",
        "predictions, true_labels = eval_model(cnn_model, test, return_binary=True)\n",
        "print_performance(predictions, true_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvE_qTbgBfLx"
      },
      "source": [
        "lengths = test_df.Sentence.str.len()\n",
        "predictions, true_labels = eval_model(rnn_model, test, return_binary=True)\n",
        "corrects_rnn = lengths[np.where(predictions == true_labels)[0]]\n",
        "predictions, true_labels = eval_model(cnn_model, test, return_binary=True)\n",
        "corrects_cnn = lengths[np.where(predictions == true_labels)[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7_oWWdFBkfb",
        "outputId": "8f34de2b-857a-4d5c-effd-be104dfd44f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.distplot(corrects_rnn, kde=False, label='RNN');\n",
        "sns.distplot(corrects_cnn, kde=False, label='CNN');\n",
        "plt.legend(loc='upper right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe2d44d9be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2lZ65Nn1bIS",
        "outputId": "c003bd7a-d7ae-4840-cbfa-e130b74d9ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "### Only validation set\n",
        "\n",
        "predictions, true_labels = eval_model(rnn_model, validation, return_binary=True)\n",
        "print_performance(predictions, true_labels)\n",
        "\n",
        "predictions, true_labels = eval_model(cnn_model, validation, return_binary=True)\n",
        "print_performance(predictions, true_labels)\n",
        "\n",
        "import statistics\n",
        "\n",
        "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "\n",
        "bert_predictions = [item for sublist in t_predictions for item in sublist]\n",
        "\n",
        "for i, v in enumerate(bert_predictions):\n",
        "    bert_predictions[i] = sigmoid(v[1])\n",
        "\n",
        "def get_majority_vote(r, c, b):\n",
        "    predictions = []\n",
        "    for i in range(len(r)):\n",
        "        predictions.append([1 if r[i] >= 0.5 else 0, 1 if c[i] >= 0.5 else 0, 1 if b[i] >= 0.5 else 0])\n",
        "    return list(map(statistics.mode, predictions))\n",
        "\n",
        "cnn_predictions, cnn_true_labels = eval_model(cnn_model, validation, return_binary=False)\n",
        "rnn_predictions, rnn_true_labels = eval_model(rnn_model, validation, return_binary=False)\n",
        "\n",
        "avg_preds = [1 if x >= 0.5 else 0 for x in np.mean((rnn_predictions, cnn_predictions), axis=0)]\n",
        "print_performance(avg_preds, cnn_true_labels)\n",
        "\n",
        "trp_preds = [1 if x >= 0.5 else 0 for x in np.mean((rnn_predictions, cnn_predictions, bert_predictions), axis=0)]\n",
        "print_performance(trp_preds, cnn_true_labels)\n",
        "\n",
        "maj_test = get_majority_vote(rnn_predictions, cnn_predictions, bert_predictions)\n",
        "print_performance(maj_test, cnn_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.710, Recall: 0.817, F1: 0.760, AUROC: 0.599\n",
            "tn=45, fp=73, fn=40, tp=179\n",
            "0.710 0.817 0.760 0.599\n",
            "Precision: 0.714, Recall: 0.776, F1: 0.744, AUROC: 0.600\n",
            "tn=50, fp=68, fn=49, tp=170\n",
            "0.714 0.776 0.744 0.600\n",
            "Precision: 0.708, Recall: 0.785, F1: 0.745, AUROC: 0.592\n",
            "tn=47, fp=71, fn=47, tp=172\n",
            "0.708 0.785 0.745 0.592\n",
            "Precision: 0.712, Recall: 0.845, F1: 0.772, AUROC: 0.605\n",
            "tn=43, fp=75, fn=34, tp=185\n",
            "0.712 0.845 0.772 0.605\n",
            "Precision: 0.710, Recall: 0.840, F1: 0.770, AUROC: 0.602\n",
            "tn=43, fp=75, fn=35, tp=184\n",
            "0.710 0.840 0.770 0.602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80p3OzYiAJgV"
      },
      "source": [
        "rnn_model = load_model('rnn_seed_' + str(seed), 'traintest')\n",
        "cnn_model = load_model('cnn_seed_' + str(seed), 'traintest')\n",
        "# bert_model = load_model('bert_seed_2', 'traintest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_P6r1H-E9r",
        "outputId": "ee4ebefc-d913-432d-bfe1-e0b3ee83d916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import statistics\n",
        "\n",
        "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "\n",
        "bert_predictions = [item for sublist in t_predictions for item in sublist]\n",
        "\n",
        "for i, v in enumerate(bert_predictions):\n",
        "    bert_predictions[i] = sigmoid(v[1])\n",
        "\n",
        "def get_majority_vote(r, c, b):\n",
        "    predictions = []\n",
        "    for i in range(len(r)):\n",
        "        predictions.append([1 if r[i] >= 0.5 else 0, 1 if c[i] >= 0.5 else 0, 1 if b[i] >= 0.5 else 0])\n",
        "    return list(map(statistics.mode, predictions))\n",
        "\n",
        "cnn_predictions, cnn_true_labels = eval_model(cnn_model, test, return_binary=False)\n",
        "rnn_predictions, rnn_true_labels = eval_model(rnn_model, test, return_binary=False)\n",
        "\n",
        "avg_preds = [1 if x >= 0.5 else 0 for x in np.mean((rnn_predictions, cnn_predictions), axis=0)]\n",
        "print_performance(avg_preds, cnn_true_labels)\n",
        "\n",
        "trp_preds = [1 if x >= 0.5 else 0 for x in np.mean((rnn_predictions, cnn_predictions, bert_predictions), axis=0)]\n",
        "print_performance(trp_preds, cnn_true_labels)\n",
        "\n",
        "maj_test = get_majority_vote(rnn_predictions, cnn_predictions, bert_predictions)\n",
        "print_performance(maj_test, cnn_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.890, Recall: 0.906, F1: 0.898, AUROC: 0.843\n",
            "tn=89, fp=25, fn=21, tp=202\n",
            "0.890 0.906 0.898 0.843\n",
            "Precision: 0.887, Recall: 0.955, F1: 0.920, AUROC: 0.859\n",
            "tn=87, fp=27, fn=10, tp=213\n",
            "0.887 0.955 0.920 0.859\n",
            "Precision: 0.891, Recall: 0.951, F1: 0.920, AUROC: 0.861\n",
            "tn=88, fp=26, fn=11, tp=212\n",
            "0.891 0.951 0.920 0.861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-y5HA1K42Fy",
        "outputId": "8e36e763-c702-41a0-9c69-882cd770fc10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### Run in loop\n",
        "\n",
        "for seed in range(15):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(1)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    train = DynamicDataset(train_sequences, train_features, train_sp_sequences, train_labels)\n",
        "\n",
        "    def run_model(network):\n",
        "        model = network(vocab_size+1, EMBEDDING_SIZE)\n",
        "        model.cuda()\n",
        "        EPOCHS = 20\n",
        "        train_model(model, train, epochs=EPOCHS, echo=False)\n",
        "        return model\n",
        "\n",
        "    rnn_model = run_model(BiLSTMShort)\n",
        "    cnn_model = run_model(MultiCnn)\n",
        "\n",
        "    print_performance(*eval_model(rnn_model, validation, return_binary=True))\n",
        "    print_performance(*eval_model(cnn_model, validation, return_binary=True))\n",
        "\n",
        "    rnn_predictions, rnn_true_labels = eval_model(rnn_model, validation, return_binary=False)\n",
        "    cnn_predictions, cnn_true_labels = eval_model(cnn_model, validation, return_binary=False)\n",
        "\n",
        "    avg_preds = [1 if x >= 0.5 else 0 for x in np.mean((rnn_predictions, cnn_predictions), axis=0)]\n",
        "    print_performance(avg_preds, true_labels)\n",
        "\n",
        "    print('*' * 50)\n",
        "\n",
        "    save_model(rnn_model, 'rnn_seed_' + str(seed), model_type='traintest')\n",
        "    save_model(cnn_model, 'cnn_seed_' + str(seed), model_type='traintest')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.750, Recall: 0.795, F1: 0.772, AUROC: 0.651\n",
            "tn=60, fp=58, fn=45, tp=174\n",
            "0.750 0.795 0.772 0.651\n",
            "Precision: 0.732, Recall: 0.763, F1: 0.747, AUROC: 0.623\n",
            "tn=57, fp=61, fn=52, tp=167\n",
            "0.732 0.763 0.747 0.623\n",
            "Precision: 0.724, Recall: 0.767, F1: 0.745, AUROC: 0.612\n",
            "tn=54, fp=64, fn=51, tp=168\n",
            "0.724 0.767 0.745 0.612\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.710, Recall: 0.817, F1: 0.760, AUROC: 0.599\n",
            "tn=45, fp=73, fn=40, tp=179\n",
            "0.710 0.817 0.760 0.599\n",
            "Precision: 0.714, Recall: 0.776, F1: 0.744, AUROC: 0.600\n",
            "tn=50, fp=68, fn=49, tp=170\n",
            "0.714 0.776 0.744 0.600\n",
            "Precision: 0.708, Recall: 0.785, F1: 0.745, AUROC: 0.592\n",
            "tn=47, fp=71, fn=47, tp=172\n",
            "0.708 0.785 0.745 0.592\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.725, Recall: 0.781, F1: 0.752, AUROC: 0.615\n",
            "tn=53, fp=65, fn=48, tp=171\n",
            "0.725 0.781 0.752 0.615\n",
            "Precision: 0.713, Recall: 0.849, F1: 0.775, AUROC: 0.607\n",
            "tn=43, fp=75, fn=33, tp=186\n",
            "0.713 0.849 0.775 0.607\n",
            "Precision: 0.725, Recall: 0.817, F1: 0.768, AUROC: 0.621\n",
            "tn=50, fp=68, fn=40, tp=179\n",
            "0.725 0.817 0.768 0.621\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.716, Recall: 0.795, F1: 0.753, AUROC: 0.605\n",
            "tn=49, fp=69, fn=45, tp=174\n",
            "0.716 0.795 0.753 0.605\n",
            "Precision: 0.729, Recall: 0.785, F1: 0.756, AUROC: 0.622\n",
            "tn=54, fp=64, fn=47, tp=172\n",
            "0.729 0.785 0.756 0.622\n",
            "Precision: 0.718, Recall: 0.804, F1: 0.759, AUROC: 0.609\n",
            "tn=49, fp=69, fn=43, tp=176\n",
            "0.718 0.804 0.759 0.609\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.710, Recall: 0.826, F1: 0.764, AUROC: 0.600\n",
            "tn=44, fp=74, fn=38, tp=181\n",
            "0.710 0.826 0.764 0.600\n",
            "Precision: 0.724, Recall: 0.790, F1: 0.755, AUROC: 0.615\n",
            "tn=52, fp=66, fn=46, tp=173\n",
            "0.724 0.790 0.755 0.615\n",
            "Precision: 0.706, Recall: 0.822, F1: 0.759, AUROC: 0.593\n",
            "tn=43, fp=75, fn=39, tp=180\n",
            "0.706 0.822 0.759 0.593\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.722, Recall: 0.831, F1: 0.773, AUROC: 0.619\n",
            "tn=48, fp=70, fn=37, tp=182\n",
            "0.722 0.831 0.773 0.619\n",
            "Precision: 0.742, Recall: 0.776, F1: 0.759, AUROC: 0.638\n",
            "tn=59, fp=59, fn=49, tp=170\n",
            "0.742 0.776 0.759 0.638\n",
            "Precision: 0.745, Recall: 0.826, F1: 0.784, AUROC: 0.651\n",
            "tn=56, fp=62, fn=38, tp=181\n",
            "0.745 0.826 0.784 0.651\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.710, Recall: 0.795, F1: 0.750, AUROC: 0.596\n",
            "tn=47, fp=71, fn=45, tp=174\n",
            "0.710 0.795 0.750 0.596\n",
            "Precision: 0.718, Recall: 0.790, F1: 0.752, AUROC: 0.607\n",
            "tn=50, fp=68, fn=46, tp=173\n",
            "0.718 0.790 0.752 0.607\n",
            "Precision: 0.721, Recall: 0.813, F1: 0.764, AUROC: 0.614\n",
            "tn=49, fp=69, fn=41, tp=178\n",
            "0.721 0.813 0.764 0.614\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.687, Recall: 0.822, F1: 0.748, AUROC: 0.564\n",
            "tn=36, fp=82, fn=39, tp=180\n",
            "0.687 0.822 0.748 0.564\n",
            "Precision: 0.700, Recall: 0.744, F1: 0.721, AUROC: 0.576\n",
            "tn=48, fp=70, fn=56, tp=163\n",
            "0.700 0.744 0.721 0.576\n",
            "Precision: 0.692, Recall: 0.790, F1: 0.738, AUROC: 0.569\n",
            "tn=41, fp=77, fn=46, tp=173\n",
            "0.692 0.790 0.738 0.569\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.723, Recall: 0.836, F1: 0.775, AUROC: 0.621\n",
            "tn=48, fp=70, fn=36, tp=183\n",
            "0.723 0.836 0.775 0.621\n",
            "Precision: 0.701, Recall: 0.772, F1: 0.735, AUROC: 0.581\n",
            "tn=46, fp=72, fn=50, tp=169\n",
            "0.701 0.772 0.735 0.581\n",
            "Precision: 0.718, Recall: 0.826, F1: 0.769, AUROC: 0.612\n",
            "tn=47, fp=71, fn=38, tp=181\n",
            "0.718 0.826 0.769 0.612\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.737, Recall: 0.795, F1: 0.765, AUROC: 0.635\n",
            "tn=56, fp=62, fn=45, tp=174\n",
            "0.737 0.795 0.765 0.635\n",
            "Precision: 0.722, Recall: 0.795, F1: 0.757, AUROC: 0.613\n",
            "tn=51, fp=67, fn=45, tp=174\n",
            "0.722 0.795 0.757 0.613\n",
            "Precision: 0.724, Recall: 0.790, F1: 0.755, AUROC: 0.615\n",
            "tn=52, fp=66, fn=46, tp=173\n",
            "0.724 0.790 0.755 0.615\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.716, Recall: 0.772, F1: 0.743, AUROC: 0.602\n",
            "tn=51, fp=67, fn=50, tp=169\n",
            "0.716 0.772 0.743 0.602\n",
            "Precision: 0.741, Recall: 0.785, F1: 0.763, AUROC: 0.638\n",
            "tn=58, fp=60, fn=47, tp=172\n",
            "0.741 0.785 0.763 0.638\n",
            "Precision: 0.738, Recall: 0.772, F1: 0.754, AUROC: 0.632\n",
            "tn=58, fp=60, fn=50, tp=169\n",
            "0.738 0.772 0.754 0.632\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.729, Recall: 0.836, F1: 0.779, AUROC: 0.630\n",
            "tn=50, fp=68, fn=36, tp=183\n",
            "0.729 0.836 0.779 0.630\n",
            "Precision: 0.698, Recall: 0.790, F1: 0.741, AUROC: 0.577\n",
            "tn=43, fp=75, fn=46, tp=173\n",
            "0.698 0.790 0.741 0.577\n",
            "Precision: 0.721, Recall: 0.813, F1: 0.764, AUROC: 0.614\n",
            "tn=49, fp=69, fn=41, tp=178\n",
            "0.721 0.813 0.764 0.614\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.742, Recall: 0.790, F1: 0.765, AUROC: 0.641\n",
            "tn=58, fp=60, fn=46, tp=173\n",
            "0.742 0.790 0.765 0.641\n",
            "Precision: 0.736, Recall: 0.790, F1: 0.762, AUROC: 0.632\n",
            "tn=56, fp=62, fn=46, tp=173\n",
            "0.736 0.790 0.762 0.632\n",
            "Precision: 0.738, Recall: 0.785, F1: 0.761, AUROC: 0.634\n",
            "tn=57, fp=61, fn=47, tp=172\n",
            "0.738 0.785 0.761 0.634\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.717, Recall: 0.822, F1: 0.766, AUROC: 0.610\n",
            "tn=47, fp=71, fn=39, tp=180\n",
            "0.717 0.822 0.766 0.610\n",
            "Precision: 0.715, Recall: 0.813, F1: 0.761, AUROC: 0.606\n",
            "tn=47, fp=71, fn=41, tp=178\n",
            "0.715 0.813 0.761 0.606\n",
            "Precision: 0.711, Recall: 0.799, F1: 0.753, AUROC: 0.599\n",
            "tn=47, fp=71, fn=44, tp=175\n",
            "0.711 0.799 0.753 0.599\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.724, Recall: 0.840, F1: 0.778, AUROC: 0.623\n",
            "tn=48, fp=70, fn=35, tp=184\n",
            "0.724 0.840 0.778 0.623\n",
            "Precision: 0.719, Recall: 0.758, F1: 0.738, AUROC: 0.604\n",
            "tn=53, fp=65, fn=53, tp=166\n",
            "0.719 0.758 0.738 0.604\n",
            "Precision: 0.704, Recall: 0.813, F1: 0.754, AUROC: 0.589\n",
            "tn=43, fp=75, fn=41, tp=178\n",
            "0.704 0.813 0.754 0.589\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVAQYaXxOM4c"
      },
      "source": [
        "# Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MHAu04FbV8F"
      },
      "source": [
        "### CNN and RNN together\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(1)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "bert_prediction_scores = [item for sublist in bert_propheno_predictions_scores for item in sublist]\n",
        "for i, v in enumerate(bert_prediction_scores):\n",
        "    bert_prediction_scores[i] = sigmoid(v[1])\n",
        "bert_prediction_scores = np.array(bert_prediction_scores)\n",
        "\n",
        "added_length = 5000\n",
        "\n",
        "rnn_val_predictions = []\n",
        "cnn_val_predictions = []\n",
        "rnn_test_predictions = []\n",
        "cnn_test_predictions = []\n",
        "\n",
        "rands = np.random.randint(propheno_df.shape[0], size=150000)\n",
        "elig_rands = np.where((bert_prediction_scores[rands] > 0.8) | (bert_prediction_scores[rands] < 0.2))[0]\n",
        "\n",
        "for i in range(0, 1):\n",
        "    instances = rands[elig_rands[i * added_length: (i+1) * added_length]]\n",
        "    \n",
        "    new_train_sequences = torch.cat((train_sequences, propheno_sequences[instances]))\n",
        "    new_train_features = torch.cat((train_features, propheno_features[instances].float()))\n",
        "    new_train_sp_sequences = torch.cat((train_sp_sequences, propheno_sp_sequences[instances]))\n",
        "    new_train_labels = torch.cat((train_labels, torch.from_numpy(bert_propheno_flat_predictions[instances].reshape(-1, 1)).float()))\n",
        "    tmp_train = DynamicDataset(new_train_sequences, new_train_features, new_train_sp_sequences, new_train_labels)\n",
        "\n",
        "    ### RNN\n",
        "    print_stats(tmp_train)\n",
        "    semi_model = BiLSTMShort(vocab_size+1, EMBEDDING_SIZE) ## BiLSTMShort\n",
        "    EPOCHS = 20\n",
        "    semi_model.cuda()\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(semi_model.parameters(), lr=0.001)\n",
        "    loader = DataLoader(tmp_train, batch_size=32)\n",
        "\n",
        "    time1 = time.time()\n",
        "    semi_model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        progress = tqdm(loader, leave=False) \n",
        "        tqdm._instances.clear()\n",
        "        for inputs, features, shorts, target in progress:\n",
        "            semi_model.zero_grad()\n",
        "            output = semi_model(inputs.to(device), features.to(device), shorts.to(device))\n",
        "            loss = criterion(output, target.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tqdm._instances.clear()\n",
        "    time2 = time.time()\n",
        "    print('Time RNN:', time2 - time1)\n",
        "    print('RNN:')\n",
        "    print_performance(*eval_model(semi_model, validation, return_binary=True))\n",
        "    print_performance(*eval_model(semi_model, test, return_binary=True))\n",
        "    rnn_val_predictions.append(eval_model(semi_model, validation, return_binary=False)[0])\n",
        "    rnn_predictions, rnn_true_labels = eval_model(semi_model, test, return_binary=False)\n",
        "    rnn_test_predictions.append(rnn_predictions)\n",
        "\n",
        "    ### CNN\n",
        "    print_stats(tmp_train)\n",
        "    semi_model = MultiCnn(vocab_size+1, EMBEDDING_SIZE)\n",
        "    EPOCHS = 20\n",
        "    semi_model.cuda()\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(semi_model.parameters(), lr=0.001)\n",
        "    loader = DataLoader(tmp_train, batch_size=32)\n",
        "\n",
        "    time1 = time.time()\n",
        "    semi_model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        progress = tqdm(loader, leave=False) # tqdm_notebook\n",
        "        tqdm._instances.clear()\n",
        "        for inputs, features, shorts, target in progress:\n",
        "            semi_model.zero_grad()\n",
        "            output = semi_model(inputs.to(device), features.to(device), shorts.to(device))\n",
        "            loss = criterion(output, target.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tqdm._instances.clear()\n",
        "        # print(epoch, loss)\n",
        "    time2 = time.time()\n",
        "    print('Time CNN:', time2 - time1)\n",
        "    print('CNN:')\n",
        "    print_performance(*eval_model(semi_model, validation, return_binary=True))\n",
        "    print_performance(*eval_model(semi_model, test, return_binary=True))\n",
        "    cnn_val_predictions.append(eval_model(semi_model, validation, return_binary=False)[0])\n",
        "    cnn_predictions, cnn_true_labels = eval_model(semi_model, test, return_binary=False)\n",
        "    cnn_test_predictions.append(cnn_predictions)\n",
        "\n",
        "    avg_preds = [1 if x >= 0.5 else 0 for x in np.mean((rnn_predictions, cnn_predictions), axis=0)]\n",
        "    print_performance(avg_preds, cnn_true_labels)\n",
        "    print('*' * 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3c7UxI4-E_L"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzVwMMgd-E_N"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pHMAtZT-E_Q"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(1)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "b_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def convert_dataset(dataset, has_labels=True):\n",
        "    sentences = dataset['Sentence']\n",
        "    sentences = ['[CLS] ' + dataset['Sentence'][i].replace('PROT', dataset['Protein'][i]).replace('PHENO', dataset['Phenotype'][i]) + ' [SEP]' for i in dataset.index]\n",
        "    if has_labels:\n",
        "        labels = [1 if label == 'Good-CoM' else 0 for label in dataset['Label']]\n",
        "    else:\n",
        "        labels = [0] * len(sentences)\n",
        "    tokenized_texts = [b_tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "    B_MAX_LEN = 100\n",
        "    input_ids = [b_tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    input_ids = pad_sequences(input_ids, maxlen=B_MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    attention_masks = []\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [np.float32(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "    return input_ids, np.array(attention_masks), np.array(labels)\n",
        "\n",
        "train_inputs, train_masks, train_b_labels = convert_dataset(train_df)\n",
        "validation_inputs, validation_masks, validation_b_labels = convert_dataset(validation_df)\n",
        "test_inputs, test_masks, test_b_labels = convert_dataset(test_df)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGCsAzRx-E_j"
      },
      "source": [
        "### Regular BERT\n",
        "\n",
        "# seed = 0\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(1)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "batch_size = 32\n",
        "scores = []\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs).long()\n",
        "validation_inputs = torch.tensor(validation_inputs).long()\n",
        "b_train_labels = torch.tensor(train_b_labels).long()\n",
        "validation_labels = torch.tensor(validation_b_labels).long()\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, b_train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "test_inputs = torch.tensor(test_inputs).long()\n",
        "b_test_labels = torch.tensor(test_b_labels).long()\n",
        "test_masks = torch.tensor(test_masks)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, b_test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                    lr=2e-5,\n",
        "                    warmup=.1)\n",
        "\n",
        "t = [] \n",
        "train_loss_set = []\n",
        "epochs = 4\n",
        "\n",
        "time1 = time.time()\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    model.train()\n",
        "\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        train_loss_set.append(loss.item())    \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "# Prediction on validation set\n",
        "model.eval()\n",
        "t_predictions , true_labels = [], []\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    t_predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "flat_predictions = [item for sublist in t_predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "print_performance(flat_predictions, flat_true_labels)\n",
        "\n",
        "\n",
        "# Prediction on test set\n",
        "model.eval()\n",
        "t_predictions , true_labels = [], []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    t_predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "flat_predictions = [item for sublist in t_predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "print_performance(flat_predictions, flat_true_labels)\n",
        "\n",
        "time2 = time.time()\n",
        "\n",
        "print(time2 - time1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAnyk0UgkCzY"
      },
      "source": [
        "with open(os.path.join(data_path, 'propheno_masks.pkl'), 'rb') as handle:\n",
        "    [propheno_inputs, propheno_masks, propheno_labels] = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRX9OQoSpsfe"
      },
      "source": [
        "### Semi-sup BERT\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(1)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "batch_size = 32\n",
        "scores = []\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs).long()\n",
        "validation_inputs = torch.tensor(validation_inputs).long()\n",
        "train_labels = torch.tensor(train_labels).long()\n",
        "validation_labels = torch.tensor(val_labels).long()\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "propheno_inputs = torch.tensor(propheno_inputs).long()\n",
        "propheno_labels = torch.tensor([[x] for x in bert_propheno_flat_predictions]).long()\n",
        "propheno_masks = torch.tensor(propheno_masks)\n",
        "\n",
        "added_length = 5000\n",
        "bert_val_predictions = []\n",
        "bert_test_predictions = []\n",
        "rands = np.random.randint(propheno_df.shape[0], size=150000)\n",
        "for i in range(0, 15): \n",
        "    instances = rands[i * added_length: (i+1) * added_length]\n",
        "    \n",
        "    tmp_train_inputs = torch.cat((train_inputs, propheno_inputs[instances]), dim=0)\n",
        "    tmp_train_masks = torch.cat((train_masks, propheno_masks[instances]), dim=0)\n",
        "    tmp_train_labels = torch.cat((train_labels, propheno_labels[instances]), dim=0)\n",
        "\n",
        "    train_data = TensorDataset(tmp_train_inputs, tmp_train_masks, tmp_train_labels)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "    validation_sampler = SequentialSampler(validation_data)\n",
        "    validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "    test_inputs = torch.tensor(test_inputs).long()\n",
        "    test_labels = torch.tensor(test_labels).long()\n",
        "    test_masks = torch.tensor(test_masks)\n",
        "\n",
        "    test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "    model.cuda()\n",
        "\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                        lr=2e-5,\n",
        "                        warmup=.1)\n",
        "\n",
        "    t = [] \n",
        "    train_loss_set = []\n",
        "    epochs = 4\n",
        "\n",
        "    for _ in trange(epochs, desc=\"Epoch\"):\n",
        "        model.train()\n",
        "\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "            optimizer.zero_grad()\n",
        "            loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "            train_loss_set.append(loss.item())    \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_examples += b_input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "\n",
        "        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "    model.eval()\n",
        "    t_predictions , true_labels = [], []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        t_predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    flat_predictions = [item for sublist in t_predictions for item in sublist]\n",
        "    # flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    bert_val_predictions.append(flat_predictions)\n",
        "\n",
        "\n",
        "    # Prediction on test set\n",
        "    model.eval()\n",
        "    t_predictions , true_labels = [], []\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        t_predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    flat_predictions = [item for sublist in t_predictions for item in sublist]\n",
        "    # flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "    flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "    bert_test_predictions.append(flat_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMnU6Bk7keMc"
      },
      "source": [
        "with open(os.path.join(data_path, 'bert_predictions_propheno_new.pkl'), 'rb') as handle:\n",
        "    [predictions, propheno_labels, flat_true_labels] = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV9L90kQOCO6"
      },
      "source": [
        "# Self-training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO0OC4ChYarn"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(1)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "length = 2000\n",
        "added_sequences = torch.tensor([], dtype=torch.long)\n",
        "added_features = torch.tensor([], dtype=torch.float)\n",
        "added_labels = torch.tensor([], dtype=torch.float)\n",
        "tmp_train = DynamicDataset(train_sequences, train_features, train_labels)\n",
        "\n",
        "for semi_idx in range(3):\n",
        "    print('Iteration #{0:d}'.format(semi_idx))\n",
        "    print_stats(tmp_train)\n",
        "    model = BiLSTM(vocab_size+1, EMBEDDING_SIZE) ## Need update\n",
        "    EPOCHS = 20\n",
        "    model.cuda()\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    loader = DataLoader(tmp_train, batch_size=32)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        progress = tqdm(loader, leave=False) # tqdm_notebook\n",
        "        tqdm._instances.clear()\n",
        "        for inputs, features, target in progress:\n",
        "            model.zero_grad()\n",
        "            output = model(inputs.to(device), features.to(device))\n",
        "            loss = criterion(output, target.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tqdm._instances.clear()\n",
        "        # print(epoch, loss)\n",
        "\n",
        "    flat_predictions, flat_true_labels = eval_model(model, propheno, threshold=1000)\n",
        "\n",
        "    instances = []\n",
        "    for i in range(semi_idx * length, (semi_idx+1) * length):\n",
        "        if flat_predictions[i][0] <= 0.02:\n",
        "            instances.append(i)\n",
        "    pos_cnt = len(instances)\n",
        "    for i in range(semi_idx * length, (semi_idx+1) * length):\n",
        "        if pos_cnt == 0:\n",
        "            break\n",
        "        if flat_predictions[i][0] >= 0.98:\n",
        "            instances.append(i)\n",
        "            pos_cnt -= 1\n",
        "    instances = np.array(instances, dtype=int)\n",
        "    if semi_idx == -2:\n",
        "        break\n",
        "    flat_predictions = np.array([1 if pred[0] >= 0.5 else 0 for pred in flat_predictions])\n",
        "    added_sequences = torch.cat((added_sequences, propheno_sequences[instances]))\n",
        "    added_features = torch.cat((added_features, propheno_features[instances].float()))\n",
        "    added_labels = torch.cat((added_labels, torch.from_numpy(flat_predictions[instances].reshape(-1, 1)).float()))\n",
        "    new_train_sequences = torch.cat((train_sequences, added_sequences))\n",
        "    new_train_features = torch.cat((train_features, added_features))\n",
        "    new_train_labels = torch.cat((train_labels, added_labels))\n",
        "    tmp_train = DynamicDataset(new_train_sequences, new_train_features, new_train_labels)\n",
        "\n",
        "    print_performance(*eval_model(model, validation, return_binary=True))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}